{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Extraction\n","\n","This script organizes the data into two columns: questions, answers"],"metadata":{"id":"maNiIR-5ZpvT"}},{"cell_type":"code","source":["# Files to clean\n","file_paths = [{'input_file': 'dialogs.txt', 'output_file': 'dialogs.json'}]\n","\n","output_dir = './output'"],"metadata":{"id":"_q-U_NcbaTaw","executionInfo":{"status":"ok","timestamp":1713993410699,"user_tz":420,"elapsed":228,"user":{"displayName":"Victor Wu","userId":"16781046719988705915"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!gdown 1Xg7UhjpdCT_3-i_X1DVQnOSkwz_PPVsx"],"metadata":{"id":"Q957wYous54a","executionInfo":{"status":"ok","timestamp":1713993412074,"user_tz":420,"elapsed":1379,"user":{"displayName":"Victor Wu","userId":"16781046719988705915"}},"outputId":"47b8a14c-c65c-4b64-afaf-7f345d68851d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1Xg7UhjpdCT_3-i_X1DVQnOSkwz_PPVsx\n","To: /content/dialogs.txt\n","\r  0% 0.00/244k [00:00<?, ?B/s]\r100% 244k/244k [00:00<00:00, 83.5MB/s]\n"]}]},{"cell_type":"markdown","source":["Berant et al.\n","\n","PDF: https://www.aclweb.org/anthology/D13-1160.pdf\n","\n","Dataset: https://github.com/brmson/dataset-factoid-webquestions\n","\n","Year of Publication: 2013\n","\n","Size: 5,810\n","\n","Data Collection: Berant et al. use the Google Suggest API as basis for generating questions. They start with a single question (\"Where was Barack Obama born\") and feed the Google Suggest API with three query fragments generated from the source question: the question without the phrase before the entity, the question without the entity and the question without the phrase after the entity. Each of these queries generates 5 candidate questions. The candidate questions are added to a queue of questions and the process is repeated for each of the questions in the queue. They stop after 1M questions are generated. Due to the nature of the approach, the generated questions start with a wh-word and revolve around a single entity. 100K of these questions are given to crowdsourcing workers who select a Freebase entity, value or list of entities as answer. Questions that are answered identically by at least two workers are included in the dataset."],"metadata":{"id":"2Dkx_9RwaFu8"}},{"cell_type":"code","source":["import json\n","\n","def data_extraction(file_path: str) -> list:\n","    \"\"\"\n","    Extracts relevant data from the JSON file and\n","    organized them into two columns: questions, answers.\n","\n","    Parameters:\n","        file_path (str): file path name to the JSON file\n","\n","    Returns:\n","        list_questions_answers (list): list of dictionaries\n","        with questions and answers\n","    \"\"\"\n","    # with open(file_path, 'r') as file:\n","    #     data = json.load(file)\n","\n","    # list_questions_answers = []\n","\n","    # for item in data:\n","\n","    #     # question = item['qText']\n","    #     # answers = item['answers']\n","    #     # for answer in answers:\n","    #     #     if answer:\n","    #     #         question_answer = {\n","    #     #             'question': question,\n","    #     #             'answer': answer\n","    #     #         }\n","    #     #         list_questions_answers.append(question_answer)\n","\n","    # return list_questions_answers\n","\n","    qa_list = []\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            question, answer = line.split('\\t')\n","            qa_dict = {'question': question.strip(), 'answer': answer.strip()}\n","            qa_list.append(qa_dict)\n","    return qa_list"],"metadata":{"id":"sAAhL6JTagIy","executionInfo":{"status":"ok","timestamp":1713993412074,"user_tz":420,"elapsed":8,"user":{"displayName":"Victor Wu","userId":"16781046719988705915"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","for file_path in file_paths:\n","    input_file = file_path['input_file']\n","    output_file = file_path['output_file']\n","    print(f\"Processing {input_file}...\\n\")\n","    list_questions_answers = data_extraction(input_file)\n","    print(f\"Number of questions and answers in {input_file}: {len(list_questions_answers)}\\n\")\n","    print(f\"First 5 entries:\\n\")\n","    for i in range(5):\n","        print(f\"Question {i+1}: {list_questions_answers[i]['question']}\")\n","        print(f\"Answer {i+1}: {list_questions_answers[i]['answer']}\\n\")\n","\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    output_file_path = os.path.join(output_dir, output_file)\n","\n","    with open(output_file_path, 'w') as file:\n","        json.dump(list_questions_answers, file)\n","    print(f\"Data saved in {output_file_path}\\n\")\n","    print(\"-\" * 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DJuFjQrd7FV","executionInfo":{"status":"ok","timestamp":1713993412074,"user_tz":420,"elapsed":5,"user":{"displayName":"Victor Wu","userId":"16781046719988705915"}},"outputId":"7e54e717-3aae-41bc-eac1-24af4c70cc9d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing dialogs.txt...\n","\n","Number of questions and answers in dialogs.txt: 3725\n","\n","First 5 entries:\n","\n","Question 1: hi, how are you doing?\n","Answer 1: i'm fine. how about yourself?\n","\n","Question 2: i'm fine. how about yourself?\n","Answer 2: i'm pretty good. thanks for asking.\n","\n","Question 3: i'm pretty good. thanks for asking.\n","Answer 3: no problem. so how have you been?\n","\n","Question 4: no problem. so how have you been?\n","Answer 4: i've been great. what about you?\n","\n","Question 5: i've been great. what about you?\n","Answer 5: i've been good. i'm in school right now.\n","\n","Data saved in ./output/train.json\n","\n","--------------------\n"]}]},{"cell_type":"code","source":["# zip the files and download\n","import shutil\n","from google.colab import files\n","from datetime import datetime\n","\n","file_name = 'dataset' + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","shutil.make_archive(file_name, 'zip', 'output')\n","files.download(file_name + '.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"m9fhmVvNe9vz","executionInfo":{"status":"ok","timestamp":1713993412274,"user_tz":420,"elapsed":203,"user":{"displayName":"Victor Wu","userId":"16781046719988705915"}},"outputId":"23041924-7ab9-4ca7-92ed-4aab389c9c37"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_7e11e014-ca7c-4126-9f81-5366998838e4\", \"dataset_20240424-211652.zip\", 65851)"]},"metadata":{}}]}]}