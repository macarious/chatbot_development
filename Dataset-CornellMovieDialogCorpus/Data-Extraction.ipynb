{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Extraction\n","\n","This script organizes the data into two columns: questions, answers"],"metadata":{"id":"RT22vI3Ws-go"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"J9t9hKIDsRWB","executionInfo":{"status":"ok","timestamp":1713672659542,"user_tz":420,"elapsed":4,"user":{"displayName":"Yifan Pan","userId":"10442134857318243994"}}},"outputs":[],"source":["# Files to clean\n","file_paths = [{'input_file': 'movie_conversations.txt', 'output_file': 'movie_dialog.json'}]\n","lines_file_path = 'movie_lines.txt'\n","\n","output_dir = './output'"]},{"cell_type":"code","source":["!gdown 1638WA6FxxfjOFtTyfg6u_eNUEg09yi5R\n","!gdown 1nTtZgWzb46nuOi9LLn922HzbbrNZyZUG"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vfcsme7ys81J","executionInfo":{"status":"ok","timestamp":1713672665836,"user_tz":420,"elapsed":6297,"user":{"displayName":"Yifan Pan","userId":"10442134857318243994"}},"outputId":"c1a6c7ab-a658-4c14-af88-7c6bfd8c1c31"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1638WA6FxxfjOFtTyfg6u_eNUEg09yi5R\n","To: /content/movie_lines.txt\n","100% 34.6M/34.6M [00:00<00:00, 106MB/s] \n","Downloading...\n","From: https://drive.google.com/uc?id=1nTtZgWzb46nuOi9LLn922HzbbrNZyZUG\n","To: /content/movie_conversations.txt\n","100% 6.76M/6.76M [00:00<00:00, 67.8MB/s]\n"]}]},{"cell_type":"markdown","source":["**Cornell Movie--Dialogs Corpus**\n","\n","Distributed together with:  Chameleons in Imagined Conversations.\n","\n","Data and Code available in ConvoKit: a toolkit for analyzing conversations\n","\n","Related corpus: Cornell Movie-Quotes Corpus\n","\n","**DESCRIPTION:**\n","                                    \n","This corpus contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts:\n","\n","- 220,579 conversational exchanges between 10,292 pairs of movie characters\n","\n","- involves 9,035 characters from 617 movies\n","\n","- in total 304,713 utterances\n","\n","- movie metadata included:\n","\n","    - genres\n","\n","    - release year\n","\n","    - IMDB rating\n","\n","    - number of IMDB votes\n","\n","    - IMDB rating\n","\n","- character metadata included:\n","\n","    - gender (for 3,774 characters)\n","\n","    - position on movie credits (3,321 characters)\n","\n","- see the [documentation](https://convokit.cornell.edu/documentation/movie.html) for details"],"metadata":{"id":"BnGeENRjtn3b"}},{"cell_type":"code","source":["def data_extraction(conversation_file_path: str, lines_file_path: str) -> list:\n","    \"\"\"\n","    Extract relevant data from the CSV file and\n","    organized them into two columns: questions, answers.\n","\n","    Parameters:\n","        conversation_file_path (str): path to the conversation file\n","        lines_file_path (str): path to the lines file\n","\n","    Returns:\n","        list_questions_answers (list): list of dictionaries\n","        with questions and answers\n","    \"\"\"\n","    # Read the movie_conversation.txt and organized the ids into questions and answers\n","    with open(conversation_file_path, 'r') as file:\n","        conversations = file.readlines()\n","\n","    list_questions_answers_id = []\n","    for conversation in conversations:\n","        conversation = conversation.strip().split(' +++$+++ ')\n","        conversation_sequence = conversation[-1].replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(',')\n","        conversation_sequence = [line_id.strip() for line_id in conversation_sequence]\n","\n","        # Include all combinations of question/answer in each conversation\n","        # for index, line_id in enumerate(conversation_sequence):\n","            # if index < len(conversation_sequence) - 1:\n","            #     question_id = line_id\n","            #     answer_id = conversation_sequence[index + 1]\n","            #     question_answer = {\n","            #         'question': question_id,\n","            #         'answer': answer_id\n","            #     }\n","            #     list_questions_answers_id.append(question_answer)\n","\n","        # Include only the first question/answer in each conversation\n","        if len(conversation_sequence) > 1:\n","            question_id = conversation_sequence[0]\n","            answer_id = conversation_sequence[1]\n","            question_answer = {\n","                'question': question_id,\n","                'answer': answer_id\n","            }\n","            list_questions_answers_id.append(question_answer)\n","\n","    # Read the movie_lines.txt and replace the ids with actual dialogue\n","    with open(lines_file_path, 'r', errors='ignore') as file:\n","        lines = file.readlines()\n","\n","    # Create dictionary of id and lines\n","    id_to_line = {}\n","    for line in lines:\n","        line = line.strip().split(' +++$+++ ')\n","        id_to_line[line[0]] = line[-1]\n","\n","    # Replace the ids with actual dialogue\n","    list_questions_answers = []\n","    for question_answer in list_questions_answers_id:\n","        question = id_to_line[question_answer['question']]\n","        answer = id_to_line[question_answer['answer']]\n","        question_answer = {\n","            'question': question,\n","            'answer': answer\n","        }\n","        list_questions_answers.append(question_answer)\n","\n","    return list_questions_answers"],"metadata":{"id":"1EWZsU4uuBzl","executionInfo":{"status":"ok","timestamp":1713672665837,"user_tz":420,"elapsed":5,"user":{"displayName":"Yifan Pan","userId":"10442134857318243994"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","\n","for file_path in file_paths:\n","    input_file = file_path['input_file']\n","    output_file = file_path['output_file']\n","    print(f\"Processing {input_file}...\\n\")\n","    list_questions_answers = data_extraction(input_file, lines_file_path)\n","    print(f\"Number of questions and answers in {input_file}: {len(list_questions_answers)}\\n\")\n","    print(f\"First 5 entries:\\n\")\n","    for i in range(5):\n","        print(f\"Question {i+1}: {list_questions_answers[i]['question']}\")\n","        print(f\"Answer {i+1}: {list_questions_answers[i]['answer']}\\n\")\n","\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    output_file_path = os.path.join(output_dir, output_file)\n","\n","    with open(output_file_path, 'w') as file:\n","        json.dump(list_questions_answers, file)\n","    print(f\"Data saved in {output_file_path}\\n\")\n","    print(\"-\" * 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sG_x5BTmuvGr","executionInfo":{"status":"ok","timestamp":1713672668472,"user_tz":420,"elapsed":2638,"user":{"displayName":"Yifan Pan","userId":"10442134857318243994"}},"outputId":"14226feb-495f-45b5-efeb-3f1daf29bca5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing movie_conversations.txt...\n","\n","Number of questions and answers in movie_conversations.txt: 83097\n","\n","First 5 entries:\n","\n","Question 1: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n","Answer 1: Well, I thought we'd start with pronunciation, if that's okay with you.\n","\n","Question 2: You're asking me out.  That's so cute. What's your name again?\n","Answer 2: Forget it.\n","\n","Question 3: No, no, it's my fault -- we didn't have a proper introduction ---\n","Answer 3: Cameron.\n","\n","Question 4: Why?\n","Answer 4: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n","\n","Question 5: Gosh, if only we could find Kat a boyfriend...\n","Answer 5: Let me see what I can do.\n","\n","Data saved in ./output/movie_dialog.json\n","\n","--------------------\n"]}]},{"cell_type":"code","source":["# zip the files and download\n","import shutil\n","from google.colab import files\n","from datetime import datetime\n","\n","file_name = 'dataset' + '_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","shutil.make_archive(file_name, 'zip', 'output')\n","files.download(file_name + '.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"K3dBOn2c0LE-","executionInfo":{"status":"ok","timestamp":1713672669506,"user_tz":420,"elapsed":1036,"user":{"displayName":"Yifan Pan","userId":"10442134857318243994"}},"outputId":"15a825b5-78d4-412f-8d91-663a27da1851"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_3a9a5b3f-26d7-4354-ac04-e4f41fc7b6ff\", \"dataset_20240421-041108.zip\", 3753269)"]},"metadata":{}}]}]}